"""
RAGç­–ç•¥æ¨¡å—ï¼šå®ç°ä¸‰ç§ä¸åŒéš¾åº¦çš„æ£€ç´¢ç­–ç•¥
"""
from typing import List, Dict, Any, Optional
from abc import ABC, abstractmethod
import re
import openai
from openai import OpenAI

from utils.vector_store import VectorStore, Reranker
from utils.difficulty_judge import DifficultyLevel
from config import config


class RAGStrategy(ABC):
    """RAGç­–ç•¥åŸºç±»"""
    
    def __init__(self, vector_store: VectorStore):
        self.vector_store = vector_store
        self.client = OpenAI(
            api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_BASE_URL
        )
        
    @abstractmethod
    def retrieve_and_answer(self, question: str) -> Dict[str, Any]:
        """æ£€ç´¢å¹¶å›ç­”é—®é¢˜"""
        pass
    
    def _call_llm(self, messages: List[Dict[str, str]], 
                  temperature: float = 0.1) -> str:
        """è°ƒç”¨LLM"""
        response = self.client.chat.completions.create(
            model=config.LLM_MODEL,
            messages=messages,
            temperature=temperature
        )
        return response.choices[0].message.content


class BasicRAGStrategy(RAGStrategy):
    """
    åŸºç¡€é¢˜ç­–ç•¥ï¼šå¤§æµ·æé’ˆ - ç²¾å‡†æ£€ç´¢
    1. å°å—åˆ†å‰²ï¼ˆ512 tokenï¼‰
    2. å‘é‡æ£€ç´¢Top Kï¼ˆæ‰©å¤§Kå€¼ï¼‰
    3. æ ¹æ®å…ƒæ•°æ®è¿‡æ»¤ï¼ˆå¹´ä»½ã€å…³é”®è¯ç­‰ï¼‰
    4. é‡æ’åºé€‰å‡ºTop 1
    5. ç”Ÿæˆç­”æ¡ˆå¹¶å¼•ç”¨æ¥æº
    """
    
    def __init__(self, vector_store: VectorStore):
        super().__init__(vector_store)
        self.reranker = Reranker()
        
    def retrieve_and_answer(self, question: str) -> Dict[str, Any]:
        """
        æ‰§è¡ŒåŸºç¡€é¢˜çš„æ£€ç´¢å’Œå›ç­”
        
        Args:
            question: é—®é¢˜æ–‡æœ¬
            
        Returns:
            åŒ…å«ç­”æ¡ˆã€æ¥æºã€æ£€ç´¢ç»“æœçš„å­—å…¸
        """
        # 1. å‘é‡æ£€ç´¢Top Kï¼ˆæ‰©å¤§æ£€ç´¢èŒƒå›´ä»¥å¢åŠ æ‰¾åˆ°æ­£ç¡®æ–‡æ¡£çš„æ¦‚ç‡ï¼‰
        top_k = config.BASIC_TOP_K * 3  # æ‰©å¤§åˆ°15ä¸ª
        search_results = self.vector_store.search(
            query=question,
            collection_type="basic",
            top_k=top_k
        )
        
        if not search_results:
            return {
                "answer": "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯",
                "sources": [],
                "retrieved_docs": []
            }
        
        # 2. æ ¹æ®å…ƒæ•°æ®è¿‡æ»¤ï¼ˆå¹´ä»½ã€å…³é”®è¯ç­‰ï¼‰
        filtered_results = self._filter_by_metadata(question, search_results)
        
        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰ç»“æœï¼Œä½¿ç”¨åŸå§‹ç»“æœ
        if not filtered_results:
            print("âš ï¸ å…ƒæ•°æ®è¿‡æ»¤åæ— ç»“æœï¼Œä½¿ç”¨åŸå§‹æ£€ç´¢ç»“æœ")
            filtered_results = search_results[:config.BASIC_TOP_K]
        
        # 3. é‡æ’åº - ä¼ é€’å…ƒæ•°æ®ï¼ŒåŒæ—¶è€ƒè™‘å†…å®¹å’Œå…ƒæ•°æ®åŒ¹é…
        documents = [result['content'] for result in filtered_results]
        metadatas = [result['metadata'] for result in filtered_results]
        reranked_indices = self.reranker.rerank(question, documents, top_k=1, metadatas=metadatas)
        
        # 4. é€‰æ‹©æœ€ç›¸å…³çš„æ–‡æ¡£
        best_result = filtered_results[reranked_indices[0]]
        
        # 4. æ„å»ºæç¤ºè¯å¹¶ç”Ÿæˆç­”æ¡ˆ
        prompt = self._build_prompt(question, best_result)
        answer = self._call_llm(prompt)
        
        # 5. æå–å¼•ç”¨ä¿¡æ¯
        sources = self._extract_sources([best_result])
        
        return {
            "answer": answer,
            "sources": sources,
            "retrieved_docs": [best_result],
            "strategy": "basic"
        }
    
    def _build_prompt(self, question: str, document: Dict[str, Any]) -> List[Dict[str, str]]:
        """æ„å»ºæç¤ºè¯"""
        source_info = document['metadata']
        source_text = f"ã€{source_info.get('source', 'æœªçŸ¥æ–‡ä»¶')}, P{source_info.get('page', '?')}ã€‘"
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„æ–‡æ¡£ç‰‡æ®µï¼Œå‡†ç¡®å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. ç›´æ¥åŸºäºæ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸è¦æ·»åŠ æ–‡æ¡£ä¸­æ²¡æœ‰çš„ä¿¡æ¯
2. ä¿æŒç­”æ¡ˆç®€æ´ã€å‡†ç¡®
3. åœ¨ç­”æ¡ˆæœ«å°¾å¿…é¡»æ³¨æ˜æ¥æºï¼Œæ ¼å¼ä¸ºï¼šã€æ–‡ä»¶å, Pé¡µç ã€‘
4. å¦‚æœæ–‡æ¡£ä¸åŒ…å«ç­”æ¡ˆæ‰€éœ€ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜"""
        
        user_prompt = f"""å‚è€ƒæ–‡æ¡£ï¼š
{source_text}
{document['content']}

é—®é¢˜ï¼š{question}

è¯·æ ¹æ®ä¸Šè¿°æ–‡æ¡£å›ç­”é—®é¢˜ï¼Œå¹¶åœ¨ç­”æ¡ˆæœ«å°¾æ ‡æ³¨æ¥æºã€‚"""
        
        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    
    def _extract_sources(self, documents: List[Dict[str, Any]]) -> List[str]:
        """æå–æ¥æºä¿¡æ¯"""
        sources = []
        for doc in documents:
            metadata = doc['metadata']
            source = f"ã€{metadata.get('source', 'æœªçŸ¥')}, P{metadata.get('page', '?')}ã€‘"
            if source not in sources:
                sources.append(source)
        return sources
    
    def _filter_by_metadata(self, question: str, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ ¹æ®é—®é¢˜ä¸­çš„å…ƒæ•°æ®ä¿¡æ¯ï¼ˆå¹´ä»½ã€å…³é”®è¯ç­‰ï¼‰è¿‡æ»¤æ£€ç´¢ç»“æœ
        
        Args:
            question: é—®é¢˜æ–‡æœ¬
            results: æ£€ç´¢ç»“æœåˆ—è¡¨
            
        Returns:
            è¿‡æ»¤åçš„ç»“æœåˆ—è¡¨
        """
        import re
        
        # 1. æå–é—®é¢˜ä¸­çš„å¹´ä»½èŒƒå›´
        year_range_pattern = r'(\d{4})\s*[-~è‡³åˆ°]\s*(\d{4})'
        year_range_match = re.search(year_range_pattern, question)
        
        query_years = []
        if year_range_match:
            start_year = int(year_range_match.group(1))
            end_year = int(year_range_match.group(2))
            query_years = list(range(start_year, end_year + 1))
        else:
            # æå–å•ä¸ªå¹´ä»½
            single_years = re.findall(r'(\d{4})', question)
            query_years = [int(y) for y in single_years if 2000 <= int(y) <= 2100]
        
        # 2. æå–é—®é¢˜ä¸­çš„å…³é”®è¯ï¼ˆå¤§å†™å­—æ¯ç»„åˆï¼Œå¦‚ERAã€SPDç­‰ï¼‰
        query_keywords = set(re.findall(r'\b[A-Z]{2,}\b', question))
        
        # 3. å¯¹ç»“æœè¿›è¡Œè¯„åˆ†å’Œè¿‡æ»¤
        scored_results = []
        for result in results:
            metadata = result['metadata']
            score = 0
            
            # å¹´ä»½åŒ¹é…è¯„åˆ†
            if query_years:
                if 'year_range_start' in metadata and 'year_range_end' in metadata:
                    doc_start = metadata['year_range_start']
                    doc_end = metadata['year_range_end']
                    # å®Œå…¨åŒ¹é…
                    if all(doc_start <= year <= doc_end for year in query_years):
                        score += 100  # é«˜åˆ†
                    # éƒ¨åˆ†åŒ¹é…
                    elif any(doc_start <= year <= doc_end for year in query_years):
                        score += 50
                elif 'year' in metadata:
                    if metadata['year'] in query_years:
                        score += 100
            
            # å…³é”®è¯åŒ¹é…è¯„åˆ†
            if query_keywords:
                # keywordsç°åœ¨æ˜¯é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ï¼Œéœ€è¦å…ˆåˆ†å‰²
                keywords_str = metadata.get('keywords', '')
                doc_keywords = set(keywords_str.split(',')) if keywords_str else set()
                matches = len(query_keywords & doc_keywords)
                score += matches * 30
            
            # æ–‡ä»¶ååŒ¹é…è¯„åˆ†ï¼ˆå…³é”®è¯åœ¨æ–‡ä»¶åä¸­å‡ºç°ï¼‰
            filename = metadata.get('filename', '').lower()
            for kw in query_keywords:
                if kw.lower() in filename:
                    score += 20
            
            scored_results.append((score, result))
        
        # 4. æŒ‰åˆ†æ•°æ’åº
        scored_results.sort(key=lambda x: x[0], reverse=True)
        
        # 5. å¦‚æœæœ€é«˜åˆ† >= 50ï¼ˆæœ‰ä¸€å®šåŒ¹é…ï¼‰ï¼Œåˆ™åªä¿ç•™é«˜åˆ†ç»“æœ
        if scored_results and scored_results[0][0] >= 50:
            # ä¿ç•™åˆ†æ•° >= æœ€é«˜åˆ†ä¸€åŠçš„ç»“æœ
            threshold = scored_results[0][0] / 2
            filtered = [result for score, result in scored_results if score >= threshold]
            
            # æ‰“å°è¿‡æ»¤ä¿¡æ¯
            print(f"ğŸ” [å…ƒæ•°æ®è¿‡æ»¤] ä» {len(results)} ä¸ªç»“æœä¸­ç­›é€‰å‡º {len(filtered)} ä¸ªé«˜åŒ¹é…åº¦æ–‡æ¡£")
            if scored_results[0][0] >= 100:
                top_source = scored_results[0][1]['metadata'].get('source', 'æœªçŸ¥')
                print(f"   âœ“ æ‰¾åˆ°å¼ºåŒ¹é…æ–‡æ¡£: {top_source}")
            
            return filtered[:config.BASIC_TOP_K]  # è¿”å›å‰Kä¸ª
        
        # 6. å¦‚æœæ²¡æœ‰æ˜æ˜¾çš„å…ƒæ•°æ®åŒ¹é…ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼ˆè®©è°ƒç”¨è€…ä½¿ç”¨åŸå§‹ç»“æœï¼‰
        return []


class IntermediateRAGStrategy(RAGStrategy):
    """
    ä¸­çº§é¢˜ç­–ç•¥ï¼šå•æ–‡æ¡£ç»¼åˆ - å®½æ³›æ£€ç´¢ + æ‘˜è¦åˆæˆ
    1. é€’å½’åˆ†å—ï¼ˆ1024 tokenï¼Œä¿æŒç« èŠ‚ç»“æ„ï¼‰
    2. æ£€ç´¢Top 10ï¼Œç¡®ä¿æ¥è‡ªåŒä¸€æ–‡æ¡£
    3. åˆæˆç»¼åˆç­”æ¡ˆ
    """
    
    def retrieve_and_answer(self, question: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œä¸­çº§é¢˜çš„æ£€ç´¢å’Œå›ç­”
        
        Args:
            question: é—®é¢˜æ–‡æœ¬
            
        Returns:
            åŒ…å«ç­”æ¡ˆã€æ¥æºã€æ£€ç´¢ç»“æœçš„å­—å…¸
        """
        # 1. å®½æ³›æ£€ç´¢
        top_k = config.INTERMEDIATE_TOP_K
        search_results = self.vector_store.search(
            query=question,
            collection_type="intermediate",
            top_k=top_k
        )
        
        if not search_results:
            return {
                "answer": "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯",
                "sources": [],
                "retrieved_docs": []
            }
        
        if not search_results:
            return {
                "answer": "æœªæ‰¾åˆ°ç›´æ¥ç›¸å…³çš„æ–‡æ¡£ï¼ˆçŸ¥è¯†åº“å¯èƒ½ä¸åŒ…å«è¯¥æ ‡å‡†ï¼‰",
                "sources": [],
                "retrieved_docs": []
            }
        
        # 2. æŒ‰æºæ–‡ä»¶åˆ†ç»„
        docs_by_source = {}
        for result in search_results:
            source = result['metadata'].get('source', 'unknown')
            if source not in docs_by_source:
                docs_by_source[source] = []
            docs_by_source[source].append(result)
        
        # 3. é€‰æ‹©æ–‡æ¡£æ•°é‡æœ€å¤šçš„æºï¼ˆæœ€ç›¸å…³çš„æ–‡æ¡£ï¼‰
        main_source = max(docs_by_source.items(), key=lambda x: len(x[1]))
        selected_docs = main_source[1]
        
        # 4. æ„å»ºæç¤ºè¯å¹¶ç”Ÿæˆç­”æ¡ˆ
        prompt = self._build_prompt(question, selected_docs)
        answer = self._call_llm(prompt)
        
        # 5. æå–å¼•ç”¨ä¿¡æ¯
        sources = self._extract_sources(selected_docs)
        
        return {
            "answer": answer,
            "sources": sources,
            "retrieved_docs": selected_docs,
            "strategy": "intermediate"
        }
    
    def _build_prompt(self, question: str, documents: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """æ„å»ºæç¤ºè¯"""
        # æ„å»ºæ–‡æ¡£å†…å®¹
        doc_content = ""
        for i, doc in enumerate(documents, 1):
            metadata = doc['metadata']
            source_info = f"ã€{metadata.get('source', 'æœªçŸ¥')}, P{metadata.get('page', '?')}ã€‘"
            doc_content += f"\n\n--- æ®µè½ {i} {source_info} ---\n{doc['content']}"
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ç»¼åˆåˆ†ææ¥è‡ªåŒä¸€æ–‡æ¡£ä¸åŒéƒ¨åˆ†çš„ä¿¡æ¯ï¼Œå½¢æˆå®Œæ•´ã€æœ‰æ¡ç†çš„ç­”æ¡ˆã€‚

è¦æ±‚ï¼š
1. è¿™äº›æ®µè½æ¥è‡ªåŒä¸€ä¸ªæ–‡æ¡£çš„ä¸åŒéƒ¨åˆ†ï¼Œè¯·å°†å®ƒä»¬ç»¼åˆèµ·æ¥å›ç­”é—®é¢˜
2. ç­”æ¡ˆè¦å…¨é¢ã€ç³»ç»Ÿï¼Œå½¢æˆå®Œæ•´çš„é€»è¾‘
3. ç­”æ¡ˆä¸­å¿…é¡»æ ‡æ³¨æ‰€æœ‰å¼•ç”¨çš„æ¥æºï¼Œæ ¼å¼ä¸ºï¼šã€æ–‡ä»¶å, Pé¡µç ã€‘
4. å¦‚æœä¸åŒæ®µè½æœ‰è¡¥å……æˆ–ç›¸å…³ä¿¡æ¯ï¼Œè¯·éƒ½çº³å…¥ç­”æ¡ˆä¸­
5. ä¿æŒç­”æ¡ˆçš„è¿è´¯æ€§å’Œæ¡ç†æ€§"""
        
        user_prompt = f"""å‚è€ƒæ–‡æ¡£ï¼ˆæ¥è‡ªåŒä¸€æ–‡æ¡£çš„ä¸åŒéƒ¨åˆ†ï¼‰ï¼š
{doc_content}

é—®é¢˜ï¼š{question}

è¯·ç»¼åˆä¸Šè¿°æ‰€æœ‰æ®µè½çš„ä¿¡æ¯ï¼Œç»™å‡ºå®Œæ•´ã€æœ‰æ¡ç†çš„ç­”æ¡ˆï¼Œå¹¶æ ‡æ³¨æ¥æºã€‚"""
        
        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    
    def _extract_sources(self, documents: List[Dict[str, Any]]) -> List[str]:
        """æå–æ¥æºä¿¡æ¯"""
        sources = set()
        for doc in documents:
            metadata = doc['metadata']
            source = f"ã€{metadata.get('source', 'æœªçŸ¥')}, P{metadata.get('page', '?')}ã€‘"
            sources.add(source)
        return sorted(list(sources))

class AdvancedRAGStrategy(RAGStrategy):
    """
    é«˜çº§é¢˜ç­–ç•¥ï¼šå¤šæ–‡æ¡£ç»¼åˆ - å¤šè½®æ£€ç´¢ + Agentæ€ç»´
    1. LLMåˆ†è§£é—®é¢˜ä¸ºå­é—®é¢˜
    2. å¯¹æ¯ä¸ªå­é—®é¢˜ç‹¬ç«‹æ£€ç´¢ï¼ˆå¯èƒ½æ¥è‡ªä¸åŒæ–‡æ¡£ï¼‰
    3. æ±‡æ€»æ‰€æœ‰ç»“æœï¼Œè¿›è¡Œå¯¹æ¯”åˆ†æ
    """
    
    def retrieve_and_answer(self, question: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œé«˜çº§é¢˜çš„æ£€ç´¢å’Œå›ç­”
        
        Args:
            question: é—®é¢˜æ–‡æœ¬
            
        Returns:
            åŒ…å«ç­”æ¡ˆã€æ¥æºã€æ£€ç´¢ç»“æœçš„å­—å…¸
        """
        # 1. åˆ†è§£é—®é¢˜
        sub_questions = self._decompose_question(question)
        
        # 2. å¯¹æ¯ä¸ªå­é—®é¢˜è¿›è¡Œæ£€ç´¢
        all_results = []
        sub_answers = []
        
        for sub_q in sub_questions:
            results = self.vector_store.search(
                query=sub_q,
                collection_type="advanced",
                top_k=5
            )
            
            if results:
                all_results.extend(results)
                # ä¸ºæ¯ä¸ªå­é—®é¢˜ç”Ÿæˆåˆæ­¥ç­”æ¡ˆ
                sub_answer = self._answer_sub_question(sub_q, results)
                sub_answers.append({
                    "question": sub_q,
                    "answer": sub_answer,
                    "sources": self._extract_sources(results)
                })
        
        # 3. å»é‡ï¼ˆåŸºäºå†…å®¹ç›¸ä¼¼åº¦ï¼‰
        unique_results = self._deduplicate_results(all_results)
        
        # 4. ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        prompt = self._build_final_prompt(question, sub_answers, unique_results)
        final_answer = self._call_llm(prompt, temperature=0.2)
        
        # 5. æå–æ‰€æœ‰æ¥æº
        all_sources = self._extract_sources(unique_results)
        
        return {
            "answer": final_answer,
            "sources": all_sources,
            "retrieved_docs": unique_results,
            "sub_questions": sub_questions,
            "sub_answers": sub_answers,
            "strategy": "advanced"
        }
    
    def _decompose_question(self, question: str) -> List[str]:
        """ä½¿ç”¨LLMåˆ†è§£å¤æ‚é—®é¢˜"""
        prompt = [
            {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªé—®é¢˜åˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸º2-4ä¸ªæ›´ç®€å•çš„å­é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. æ¯ä¸ªå­é—®é¢˜åº”è¯¥ç‹¬ç«‹ä¸”æ˜ç¡®
2. å­é—®é¢˜çš„ç­”æ¡ˆç»„åˆèµ·æ¥èƒ½å¤Ÿå›ç­”åŸé—®é¢˜
3. å¦‚æœé—®é¢˜æ¶‰åŠæ¯”è¾ƒï¼Œåº”è¯¥ä¸ºæ¯ä¸ªå¯¹è±¡åˆ›å»ºç‹¬ç«‹çš„å­é—®é¢˜
4. ç›´æ¥è¾“å‡ºå­é—®é¢˜åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œå‰é¢åŠ åºå·"""},
            {"role": "user", "content": f"è¯·å°†ä»¥ä¸‹é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜ï¼š\n{question}"}
        ]
        
        response = self._call_llm(prompt, temperature=0.1)
        
        # è§£æå­é—®é¢˜
        sub_questions = []
        for line in response.strip().split('\n'):
            # ç§»é™¤åºå·å’Œç©ºç™½
            cleaned = line.strip()
            if cleaned and len(cleaned) > 5:
                # ç§»é™¤å¼€å¤´çš„æ•°å­—ã€ç‚¹ã€æ‹¬å·ç­‰
                import re
                cleaned = re.sub(r'^[\d\.\))\]ã€]+\s*', '', cleaned)
                if cleaned:
                    sub_questions.append(cleaned)
        
        # å¦‚æœåˆ†è§£å¤±è´¥ï¼Œä½¿ç”¨åŸé—®é¢˜
        if not sub_questions:
            sub_questions = [question]
        
        return sub_questions
    
    def _answer_sub_question(self, sub_question: str, 
                            documents: List[Dict[str, Any]]) -> str:
        """å›ç­”å­é—®é¢˜"""
        doc_content = ""
        for i, doc in enumerate(documents[:2], 1):  # æœ€å¤šä½¿ç”¨2ä¸ªæ–‡æ¡£
            metadata = doc['metadata']
            source_info = f"ã€{metadata.get('source', 'æœªçŸ¥')}, P{metadata.get('page', '?')}ã€‘"
            # æˆªå–å‰400å­—ç¬¦
            content_brief = doc['content'][:400]
            doc_content += f"\n[æ–‡æ¡£{i}] {source_info}\n{content_brief}...\n"
        
        prompt = [
            {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šé—®ç­”åŠ©æ‰‹ã€‚ç®€æ´å›ç­”é—®é¢˜ã€‚"},
            {"role": "user", "content": f"æ–‡æ¡£ï¼š\n{doc_content}\n\né—®é¢˜ï¼š{sub_question}\n\nç®€è¦å›ç­”ï¼š"}
        ]
        
        return self._call_llm(prompt)
    
    def _build_final_prompt(self, question: str, sub_answers: List[Dict[str, Any]],
                           documents: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """æ„å»ºæœ€ç»ˆç­”æ¡ˆçš„æç¤ºè¯"""
        # æ„å»ºå­é—®é¢˜ç­”æ¡ˆæ€»ç»“ï¼ˆç²¾ç®€ç‰ˆï¼Œæ¯ä¸ªç­”æ¡ˆæœ€å¤š200å­—ï¼‰
        sub_answers_text = ""
        for i, sub in enumerate(sub_answers, 1):
            sources_str = "ã€".join(sub['sources'][:2])  # åªå–å‰2ä¸ªæ¥æº
            answer_brief = sub['answer'][:200] + "..." if len(sub['answer']) > 200 else sub['answer']
            sub_answers_text += f"\n{i}. {sub['question']}\n   {answer_brief}\n   æ¥æºï¼š{sources_str}\n"
        
        # æ„å»ºæ”¯æ’‘æ–‡æ¡£ï¼ˆæœ€å¤š5ä¸ªï¼Œæ¯ä¸ªæœ€å¤š300å­—ç¬¦ï¼‰
        docs_text = ""
        seen_contents = set()
        doc_count = 0
        for doc in documents:
            if doc_count >= 5:  # æœ€å¤š5ä¸ªæ–‡æ¡£
                break
            content = doc['content'][:300]  # æˆªå–å‰300å­—ç¬¦
            if content not in seen_contents:
                metadata = doc['metadata']
                source_info = f"ã€{metadata.get('source', 'æœªçŸ¥')}, P{metadata.get('page', '?')}ã€‘"
                docs_text += f"\n[æ–‡æ¡£{doc_count+1}] {source_info}\n{content}...\n"
                seen_contents.add(content)
                doc_count += 1
        
        system_prompt = """ä½ æ˜¯ä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£åˆ†æåŠ©æ‰‹ã€‚åŸºäºå¤šä¸ªæ–‡æ¡£ä¿¡æ¯è¿›è¡Œç»¼åˆåˆ†æã€‚

è¦æ±‚ï¼š
1. ç»¼åˆå­é—®é¢˜ç­”æ¡ˆå’Œæ–‡æ¡£ä¿¡æ¯
2. å¯¹æ¯”ä¸åŒæ–‡æ¡£çš„å·®å¼‚
3. ç­”æ¡ˆç®€æ´æ¸…æ™°ï¼Œåˆ†ç‚¹é˜è¿°
4. å¿…é¡»æ ‡æ³¨æ¥æºï¼šã€æ–‡ä»¶å, Pé¡µç ã€‘"""
        
        user_prompt = f"""é—®é¢˜ï¼š{question}

å­é—®é¢˜åˆ†æï¼š
{sub_answers_text}

å‚è€ƒæ–‡æ¡£ï¼š
{docs_text}

è¯·ç»¼åˆå›ç­”ï¼Œæ ‡æ³¨æ¥æºã€‚"""
        
        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    
    def _deduplicate_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å»é™¤é‡å¤çš„æ£€ç´¢ç»“æœ"""
        seen = set()
        unique = []
        
        for result in results:
            # ä½¿ç”¨å†…å®¹çš„å‰100å­—ç¬¦ä½œä¸ºå»é‡ä¾æ®
            key = result['content'][:100]
            if key not in seen:
                seen.add(key)
                unique.append(result)
        
        return unique
    
    def _extract_sources(self, documents: List[Dict[str, Any]]) -> List[str]:
        """æå–æ¥æºä¿¡æ¯"""
        sources = set()
        for doc in documents:
            metadata = doc['metadata']
            source = f"ã€{metadata.get('source', 'æœªçŸ¥')}, P{metadata.get('page', '?')}ã€‘"
            sources.add(source)
        return sorted(list(sources))


class RAGStrategyFactory:
    """RAGç­–ç•¥å·¥å‚"""
    
    @staticmethod
    def create_strategy(difficulty: DifficultyLevel, 
                       vector_store: VectorStore) -> RAGStrategy:
        """
        æ ¹æ®éš¾åº¦åˆ›å»ºå¯¹åº”çš„RAGç­–ç•¥
        
        Args:
            difficulty: éš¾åº¦ç­‰çº§
            vector_store: å‘é‡æ•°æ®åº“
            
        Returns:
            å¯¹åº”çš„RAGç­–ç•¥å®ä¾‹
        """
        if difficulty == DifficultyLevel.BASIC:
            return BasicRAGStrategy(vector_store)
        elif difficulty == DifficultyLevel.INTERMEDIATE:
            return IntermediateRAGStrategy(vector_store)
        elif difficulty == DifficultyLevel.ADVANCED:
            return AdvancedRAGStrategy(vector_store)
        else:
            raise ValueError(f"æœªçŸ¥çš„éš¾åº¦ç­‰çº§: {difficulty}")
